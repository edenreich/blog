name: api

on:
  push:
    branches:
      - master
      - develop
      - adjust-api-workflow
    paths:
      - ".github/workflows/api.yml"
      - "src/backend/api/**"
      - "ops/on-premises/docker/backend/api/**"
      - "ops/on-premises/kubernetes/backend/api/**"

env:
  DOCKER_BUILDKIT: 1
  DOCKER_REPO: edenr/blog-api 
  DOCKER_REPO_DEV: edenr/blog-api-devtools
  STAGING_SERVERS: k8s-master k8s-node1 k8s-node2 k8s-node3 k8s-node4 k8s-node5 k8s-node6
  PRODUCTION_SERVERS: k4s-master k4s-node1 k4s-node2 k4s-node3 k4s-node4
  DEPLOYMENT_NAME: api
  DEPLOYMENT_VERSION: $(echo ${{ github.event.after }} | cut -c1-8)
  DEPLOYMENT_PREVIOUS_VERSION: $(echo ${{ github.event.before }} | cut -c1-8)

jobs:
  docker_login:
    runs-on: self-hosted
    steps:
      - name: Add docker login credentials to github-runner server
        run: |
          echo ${{ secrets.DOCKER_CONFIG_JSON }} | base64 -d > ~/.docker/config.json
          docker login
  update_secrets_staging:
    runs-on: self-hosted
    environment:
      name: staging
    steps:
      - uses: actions/checkout@master
      - name: Kubernetes - switch to staging context
        run: |
          kubectl config use-context staging
      - name: Kubernetes - update secrets in the cluster
        run: |
          API_DATABASE_URL=${{ secrets.API_DATABASE_URL }} \
          API_TEST_DATABASE_URL=${{ secrets.API_TEST_DATABASE_URL }} \
          API_JWT_PASSPHRASE=${{ secrets.API_JWT_PASSPHRASE }} \
          API_JWT_PUBLIC_KEY=${{ secrets.API_JWT_PUBLIC_KEY }} \
          API_JWT_SECRET_KEY=${{ secrets.API_JWT_SECRET_KEY }} \
          API_GOOGLE_APPLICATION_CREDENTIALS=${{ secrets.API_GOOGLE_APPLICATION_CREDENTIALS }} \
          envsubst < ops/on-premises/kubernetes/secrets/api.yaml | kubectl apply -f -
      - name: Kubernetes - add docker pull secrets if not exists
        run: |
          DOCKER_CONFIG_JSON=${{ secrets.DOCKER_CONFIG_JSON }} \
          envsubst < ops/on-premises/kubernetes/secrets/container_registry.yaml | kubectl apply -f -
  update_secrets_production:
    runs-on: self-hosted
    environment:
      name: production
    steps:
      - uses: actions/checkout@master
      - name: Kubernetes - switch to production context
        run: |
          kubectl config use-context production
      - name: Kubernetes - update secrets in the cluster
        run: |
          API_DATABASE_URL=${{ secrets.API_DATABASE_URL }} \
          API_TEST_DATABASE_URL=${{ secrets.API_TEST_DATABASE_URL }} \
          API_JWT_PASSPHRASE=${{ secrets.API_JWT_PASSPHRASE }} \
          API_JWT_PUBLIC_KEY=${{ secrets.API_JWT_PUBLIC_KEY }} \
          API_JWT_SECRET_KEY=${{ secrets.API_JWT_SECRET_KEY }} \
          API_GOOGLE_APPLICATION_CREDENTIALS=${{ secrets.API_GOOGLE_APPLICATION_CREDENTIALS }} \
          envsubst < ops/on-premises/kubernetes/secrets/api.yaml | kubectl apply -f -
      - name: Kubernetes - add docker pull secrets if not exists
        run: |
          DOCKER_CONFIG_JSON=${{ secrets.DOCKER_CONFIG_JSON }} \
          envsubst < ops/on-premises/kubernetes/secrets/container_registry.yaml | kubectl apply -f -
  build:
    runs-on: self-hosted
    needs: docker_login
    steps:
      - uses: actions/checkout@master
      - name: Docker - build container image
        run: |
          docker build \
            --target production \
            --cache-from ${{ env.DOCKER_REPO }}:latest \
            -t ${{ env.DOCKER_REPO }}:latest \
            -f ops/on-premises/docker/backend/api/Dockerfile .
      - name: Docker - build test container image
        run: |
          docker build \
            --target src-with-devtools \
            --cache-from ${{ env.DOCKER_REPO_DEV }}:latest \
            -t ${{ env.DOCKER_REPO_DEV }}:latest \
            -f ops/on-premises/docker/backend/api/Dockerfile .
      - name: Docker - tag container images
        run: |
          docker tag ${{ env.DOCKER_REPO }}:latest ${{ env.DOCKER_REPO }}:${{ env.DEPLOYMENT_VERSION }}
          docker tag ${{ env.DOCKER_REPO_DEV }}:latest ${{ env.DOCKER_REPO_DEV }}:${{ env.DEPLOYMENT_VERSION }}
  push:
    needs: build
    runs-on: self-hosted
    steps:
      - name: Docker - push image to registry
        run: |
          docker push ${{ env.DOCKER_REPO }}:${{ env.DEPLOYMENT_VERSION }}
          docker push ${{ env.DOCKER_REPO_DEV }}:${{ env.DEPLOYMENT_VERSION }}
          docker push ${{ env.DOCKER_REPO }}:latest
          docker push ${{ env.DOCKER_REPO_DEV }}:latest
  lint:
    needs: push
    runs-on: self-hosted
    environment:
      name: staging
    steps:
      - name: Kubernetes - switch to staging context
        run: |
          kubectl config use-context staging
      - name: Kubernetes - run linter
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO_DEV }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/linting.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-linting-${{ env.DEPLOYMENT_VERSION }}
  analyse:
    needs: push
    runs-on: self-hosted
    environment:
      name: staging
    steps:
      - name: Kubernetes - switch to staging context
        run: |
          kubectl config use-context staging
      - name: Kubernetes - run static analysis
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO_DEV }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/analyse.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-code-analysis-${{ env.DEPLOYMENT_VERSION }}
  test:
    needs: push
    runs-on: self-hosted
    environment:
      name: staging
    steps:
      - name: Kubernetes - switch to staging context
        run: |
          kubectl config use-context staging
      - name: Kubernetes - run job for database migrations
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO_DEV }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/tests/migrations.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-test-database-migration-${{ env.DEPLOYMENT_VERSION }}
      - name: Kubernetes - run job for loading fixture database seeds
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO_DEV }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/tests/seed.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-test-database-seed-${{ env.DEPLOYMENT_VERSION }}
      - name: Kubernetes - run job for integration tests
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO_DEV }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/tests/run.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-integration-tests-${{ env.DEPLOYMENT_VERSION }}
  deploy_staging:
    needs: [lint, analyse, test]
    runs-on: self-hosted
    environment:
      name: staging
      url: https://stage-api.eden-reich.com
    steps:
      - uses: actions/checkout@master
      - name: Kubernetes - switch to staging context
        run: |
          kubectl config use-context staging
      - name: Kubernetes - run database migrations
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/migrations.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-database-migration-${{ env.DEPLOYMENT_VERSION }}
      - name: Kubernetes - create a new deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO }} \
          envsubst < ops/on-premises/kubernetes/backend/api/deployment.yaml | kubectl apply -f -
      - name: Kubernetes - wait for new deployment to be successfully rolled out
        run: |
          max_count=60
          count=0
          while [ true ]; do
            if [[ $count -gt $max_count ]]; then
              echo "===> Waited for too long for a successful rolled out green version, but something went wrong. Aborting..."
              exit 1
            fi
            if [[ $(kubectl rollout status deploy/${{ env.DEPLOYMENT_NAME }}-${{ env.DEPLOYMENT_VERSION }} --timeout=5s 2>/dev/null | grep 'successfully rolled out') ]]; then
              echo "=====> Green deployment has been successfully rolled out. Continuing..."
              break
            fi
            count=$((count+1))
            echo "===> Green deployment ${{ env.DEPLOYMENT_NAME }}-${{ env.DEPLOYMENT_VERSION }} is being rolled out...Waiting..."
            sleep 1
          done
      - name: Kubernetes - apply horizontal pods autoscaling to new deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          envsubst < ops/on-premises/kubernetes/backend/api/hpa.yaml | kubectl apply -f -
      - name: Kubernetes - switch LB to green deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          envsubst < ops/on-premises/kubernetes/backend/api/service.yaml | kubectl apply -f -
      - name: Kubernetes - remove completed jobs
        run: kubectl delete jobs $(kubectl get jobs | grep ${{ env.DEPLOYMENT_NAME }} | grep 1/1 | awk '{ print $1 }' | xargs) || true
  deploy_production:
    if: github.event.ref == 'refs/heads/master'
    needs: deploy_staging
    runs-on: self-hosted
    environment:
      name: production
      url: https://api.eden-reich.com
    steps:
      - uses: actions/checkout@master
      - name: Kubernetes - switch to production context
        run: |
          kubectl config use-context production
      - name: Kubernetes - run database migrations
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/migrations.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-database-migration-${{ env.DEPLOYMENT_VERSION }}
      - name: Kubernetes - create a new deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO }} \
          envsubst < ops/on-premises/kubernetes/backend/api/deployment.yaml | kubectl apply -f -
      - name: Kubernetes - wait for new deployment to be successfully rolled out
        run: |
          max_count=60
          count=0
          while [ true ]; do
            if [[ $count -gt $max_count ]]; then
              echo "===> Waited for too long for a successful rolled out green version, but something went wrong. Aborting..."
              exit 1
            fi
            if [[ $(kubectl rollout status deploy/${{ env.DEPLOYMENT_NAME }}-${{ env.DEPLOYMENT_VERSION }} --timeout=5s 2>/dev/null | grep 'successfully rolled out') ]]; then
              echo "=====> Green deployment has been successfully rolled out. Continuing..."
              break
            fi
            count=$((count+1))
            echo "===> Green deployment ${{ env.DEPLOYMENT_NAME }}-${{ env.DEPLOYMENT_VERSION }} is being rolled out...Waiting..."
            sleep 1
          done
      - name: Kubernetes - apply horizontal pods autoscaling to new deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          envsubst < ops/on-premises/kubernetes/backend/api/hpa.yaml | kubectl apply -f -
      - name: Kubernetes - switch LB to green deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_VERSION }} \
          envsubst < ops/on-premises/kubernetes/backend/api/service.yaml | kubectl apply -f -
      - name: Kubernetes - remove completed jobs
        run: kubectl delete jobs $(kubectl get jobs | grep ${{ env.DEPLOYMENT_NAME }} | grep 1/1 | awk '{ print $1 }' | xargs) || true
  revert_production:
    name: Revert production
    needs: deploy_production
    runs-on: self-hosted
    environment:
      name: production
      url: https://api.eden-reich.com
    steps:
      - name: Kubernetes - switch to production context
        run: |
          kubectl config use-context production
      - name: Kubernetes - revert database migrations to previous version
        run: |
          VERSION=${{ env.DEPLOYMENT_PREVIOUS_VERSION }} \
          REPOSITORY=${{ env.DOCKER_REPO }} \
          envsubst < ops/on-premises/kubernetes/backend/api/jobs/migrations.yaml | kubectl apply -f -
          ./ops/on-premises/kubernetes/utils/wait_for_job.sh api-database-revert-migration-${{ env.DEPLOYMENT_PREVIOUS_VERSION }}
      - name: Kubernetes - apply horizontal pods autoscaling to previous deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_PREVIOUS_VERSION }} \
          envsubst < ops/on-premises/kubernetes/backend/api/hpa.yaml | kubectl apply -f -
      - name: Kubernetes - switch LB to previous deployment
        run: |
          VERSION=${{ env.DEPLOYMENT_PREVIOUS_VERSION }} \
          envsubst < ops/on-premises/kubernetes/backend/api/service.yaml | kubectl apply -f -
      - name: Kubernetes - remove completed jobs
        run: kubectl delete jobs $(kubectl get jobs | grep ${{ env.DEPLOYMENT_NAME }} | grep 1/1 | awk '{ print $1 }' | xargs) || true
  cleanup:
    runs-on: self-hosted
    needs: deploy_staging
    steps:
      - name: Github-runner - remove all related images except latest
        run: |
          docker rmi -f $(docker images | grep ${{ env.DOCKER_REPO }} | grep -v latest | awk '{image = sprintf("%s:%s", $1, $2); print image}' | xargs) || true
          docker rmi -f $(docker images | grep ${{ env.DOCKER_REPO_DEV }} | grep -v latest | awk '{image = sprintf("%s:%s", $1, $2); print image}' | xargs) || true
      - name: Github-runner - remove dangling docker images
        run: docker system prune -f
      - name: Keep 2 deployments available for rollback
        run: |
          kubectl delete deployments \
            $(kubectl get deployments --sort-by=.metadata.creationTimestamp | grep ${{ env.DEPLOYMENT_NAME }} | awk '{ print $1 }' | head -n -2 | xargs) || true
      - name: Staging worker nodes - remove all dangling images
        if: github.event.ref == 'refs/heads/develop'
        run: |
          for server in $(echo ${{ env.STAGING_SERVERS }} | xargs); do ssh $server ./scripts/cleanup.sh; done
      - name: Production worker nodes - remove all dangling images
        if: github.event.ref == 'refs/heads/master'
        run: |
          for server in $(echo ${{ env.PRODUCTION_SERVERS }} | xargs); do ssh $server ./scripts/cleanup.sh; done
